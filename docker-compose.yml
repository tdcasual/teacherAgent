services:
  api:
    build:
      context: .
      dockerfile: services/api/Dockerfile
    command: ["uvicorn", "services.api.app:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "${API_WORKERS:-2}"]
    ports:
      - "8000:8000"
    env_file: .env
    environment:
      - DATA_DIR=/app/data
      - UPLOADS_DIR=/app/uploads
      - JOB_QUEUE_BACKEND=rq
      - REDIS_URL=redis://:${REDIS_PASSWORD:-physics_edu_2026}@redis:6379/0
      - QDRANT_PATH=/app/.qdrant
      - MEM0_DIR=/app/.mem0
      - LLM_MAX_CONCURRENCY_STUDENT=${LLM_MAX_CONCURRENCY_STUDENT:-12}
      - LLM_MAX_CONCURRENCY_TEACHER=${LLM_MAX_CONCURRENCY_TEACHER:-2}
      - CHAT_STUDENT_INFLIGHT_LIMIT=${CHAT_STUDENT_INFLIGHT_LIMIT:-1}
      - CHAT_MAX_MESSAGES_STUDENT=${CHAT_MAX_MESSAGES_STUDENT:-40}
      - PROFILE_UPDATE_ASYNC=${PROFILE_UPDATE_ASYNC:-1}
      - PROFILE_CACHE_TTL_SEC=${PROFILE_CACHE_TTL_SEC:-10}
      - ASSIGNMENT_DETAIL_CACHE_TTL_SEC=${ASSIGNMENT_DETAIL_CACHE_TTL_SEC:-10}
      - DEFAULT_TEACHER_ID=${DEFAULT_TEACHER_ID:-teacher}
      - AUTH_REQUIRED=${AUTH_REQUIRED:-0}
    volumes:
      - ./data:/app/data
      - ./.qdrant:/app/.qdrant
      - ./.mem0:/app/.mem0
      - ./uploads:/app/uploads
    depends_on:
      - redis
    restart: unless-stopped
    mem_limit: 2g
    cpus: 2.0
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 5s
      retries: 3

  mcp:
    build:
      context: .
      dockerfile: services/mcp/Dockerfile
    ports:
      - "9000:9000"
    env_file: .env
    environment:
      - DATA_DIR=/app/data
      - MCP_API_KEY=${MCP_API_KEY:-}
    volumes:
      - ./data:/app/data
      - ./.qdrant:/app/.qdrant
      - ./.mem0:/app/.mem0
      - ./uploads:/app/uploads
    restart: unless-stopped
    mem_limit: 1g
    cpus: 1.0
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:9000/health')"]
      interval: 30s
      timeout: 5s
      retries: 3

  worker:
    build:
      context: .
      dockerfile: services/api/Dockerfile
    command: ["python3", "-m", "services.api.workers.rq_worker"]
    env_file: .env
    environment:
      - DATA_DIR=/app/data
      - UPLOADS_DIR=/app/uploads
      - JOB_QUEUE_BACKEND=rq
      - REDIS_URL=redis://:${REDIS_PASSWORD:-physics_edu_2026}@redis:6379/0
      - RQ_SCAN_PENDING_ON_START=${RQ_SCAN_PENDING_ON_START:-0}
    volumes:
      - ./data:/app/data
      - ./.qdrant:/app/.qdrant
      - ./.mem0:/app/.mem0
      - ./uploads:/app/uploads
    depends_on:
      - redis
    restart: unless-stopped
    mem_limit: 2g
    cpus: 2.0
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'rq worker' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:-physics_edu_2026}
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-physics_edu_2026}", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  frontend_student:
    build:
      context: .
      dockerfile: frontend/Dockerfile.student
      args:
        VITE_API_URL: ${VITE_API_URL:-http://localhost:8000}
    ports:
      - "3001:80"
    depends_on:
      - api
    restart: unless-stopped
    mem_limit: 256m
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:80/ || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  frontend_teacher:
    build:
      context: .
      dockerfile: frontend/Dockerfile.teacher
      args:
        VITE_API_URL: ${VITE_API_URL:-http://localhost:8000}
    ports:
      - "3002:80"
    depends_on:
      - api
    restart: unless-stopped
    mem_limit: 256m
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:80/ || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  backup_scheduler:
    build:
      context: .
      dockerfile: services/backup/Dockerfile
    profiles: ["backup"]
    command:
      - bash
      - -lc
      - |
        while true; do
          bash scripts/backup/run_backup.sh --snapshot-type incremental --target "${BACKUP_TARGET_DEFAULT:-s3}"
          sleep "${BACKUP_INCREMENTAL_INTERVAL_SEC:-300}"
        done
    env_file: .env
    environment:
      - BACKUP_NAMESPACE=${BACKUP_NAMESPACE:-prod}
      - BACKUP_TARGET_DEFAULT=${BACKUP_TARGET_DEFAULT:-s3}
      - BACKUP_HOT_DAYS=${BACKUP_HOT_DAYS:-30}
      - BACKUP_COLD_DAYS=${BACKUP_COLD_DAYS:-180}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-}
      - S3_BUCKET=${S3_BUCKET:-}
      - OSS_ACCESS_KEY_ID=${OSS_ACCESS_KEY_ID:-}
      - OSS_ACCESS_KEY_SECRET=${OSS_ACCESS_KEY_SECRET:-}
      - OSS_ENDPOINT=${OSS_ENDPOINT:-}
      - OSS_BUCKET=${OSS_BUCKET:-}
    volumes:
      - ./:/workspace
      - ./data:/workspace/data:ro
      - ./uploads:/workspace/uploads:ro
      - ./output:/workspace/output
    restart: unless-stopped

  backup_daily_full:
    build:
      context: .
      dockerfile: services/backup/Dockerfile
    profiles: ["backup"]
    command:
      - bash
      - -lc
      - |
        while true; do
          sleep "${BACKUP_DAILY_FULL_INTERVAL_SEC:-86400}"
          bash scripts/backup/run_backup.sh --snapshot-type full --target "${BACKUP_TARGET_DEFAULT:-s3}"
        done
    env_file: .env
    environment:
      - BACKUP_NAMESPACE=${BACKUP_NAMESPACE:-prod}
      - BACKUP_TARGET_DEFAULT=${BACKUP_TARGET_DEFAULT:-s3}
      - BACKUP_HOT_DAYS=${BACKUP_HOT_DAYS:-30}
      - BACKUP_COLD_DAYS=${BACKUP_COLD_DAYS:-180}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-}
      - S3_BUCKET=${S3_BUCKET:-}
      - OSS_ACCESS_KEY_ID=${OSS_ACCESS_KEY_ID:-}
      - OSS_ACCESS_KEY_SECRET=${OSS_ACCESS_KEY_SECRET:-}
      - OSS_ENDPOINT=${OSS_ENDPOINT:-}
      - OSS_BUCKET=${OSS_BUCKET:-}
    volumes:
      - ./:/workspace
      - ./data:/workspace/data:ro
      - ./uploads:/workspace/uploads:ro
      - ./output:/workspace/output
    restart: unless-stopped

  backup_verify_weekly:
    build:
      context: .
      dockerfile: services/backup/Dockerfile
    profiles: ["backup"]
    command:
      - bash
      - -lc
      - |
        while true; do
          sleep "${BACKUP_VERIFY_INTERVAL_SEC:-604800}"
          bash scripts/backup/verify_restore.sh --target "${BACKUP_TARGET_DEFAULT:-s3}"
        done
    env_file: .env
    environment:
      - BACKUP_NAMESPACE=${BACKUP_NAMESPACE:-prod}
      - BACKUP_TARGET_DEFAULT=${BACKUP_TARGET_DEFAULT:-s3}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-}
      - S3_BUCKET=${S3_BUCKET:-}
      - OSS_ACCESS_KEY_ID=${OSS_ACCESS_KEY_ID:-}
      - OSS_ACCESS_KEY_SECRET=${OSS_ACCESS_KEY_SECRET:-}
      - OSS_ENDPOINT=${OSS_ENDPOINT:-}
      - OSS_BUCKET=${OSS_BUCKET:-}
    volumes:
      - ./:/workspace
      - ./output:/workspace/output
    restart: unless-stopped

  # Optional Qdrant service (enable with: docker compose --profile qdrant up)
  qdrant:
    image: qdrant/qdrant:latest
    profiles: ["qdrant"]
    ports:
      - "6333:6333"
    volumes:
      - ./.qdrant:/qdrant/storage

volumes:
  redis_data:
